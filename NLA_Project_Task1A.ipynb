{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLA_Project_Task1A.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e7bed5da6cf4b34803c7484e2e35d9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_749f3875638c4c4da07659aa4d922617",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6ec7d043dcc94accbb5c79789ea6d3bd",
              "IPY_MODEL_08c2f8ceb6a8483fa9304537f4a4314f"
            ]
          }
        },
        "749f3875638c4c4da07659aa4d922617": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6ec7d043dcc94accbb5c79789ea6d3bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d59699f8d54145b8a6cffc0ee7df2628",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 385,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 385,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a6017df065ac48e58647b525484421f8"
          }
        },
        "08c2f8ceb6a8483fa9304537f4a4314f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9cf9bc2b0b1e4106a0417c9ee7326cc1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 385/385 [00:01&lt;00:00, 368B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_08ac88ba2b4e466aa77b50ccbaa23dbb"
          }
        },
        "d59699f8d54145b8a6cffc0ee7df2628": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a6017df065ac48e58647b525484421f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9cf9bc2b0b1e4106a0417c9ee7326cc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "08ac88ba2b4e466aa77b50ccbaa23dbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc12830b3dec4b9990ae35465fe4b1bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ff107716040342a59f9ea9744121fe16",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b6a4d2b7da6846a6bee0d67e3683eecd",
              "IPY_MODEL_64c52d73b7af4ad4a926897a0c580d08"
            ]
          }
        },
        "ff107716040342a59f9ea9744121fe16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b6a4d2b7da6846a6bee0d67e3683eecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d8b57092c4fa44f6a4fbe20d5f89cc48",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 227845,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 227845,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7f27a04fcea64fc8aeffb11ad54b4966"
          }
        },
        "64c52d73b7af4ad4a926897a0c580d08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_728649b2a6144772a04067f6a5680133",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 228k/228k [00:00&lt;00:00, 337kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d8e3c6379d7b46c597ffffcbdee612e1"
          }
        },
        "d8b57092c4fa44f6a4fbe20d5f89cc48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7f27a04fcea64fc8aeffb11ad54b4966": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "728649b2a6144772a04067f6a5680133": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d8e3c6379d7b46c597ffffcbdee612e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8c07a2238fa420a9424811fcd72a217": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d760618999c34c9f8c3dd42730f415f2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4a9c68bd6e534bc39f4f70a424a5e621",
              "IPY_MODEL_1ffaa617975d43b1863fb6b1de7c09b0"
            ]
          }
        },
        "d760618999c34c9f8c3dd42730f415f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4a9c68bd6e534bc39f4f70a424a5e621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e6a3b17db176412082fd1ac974edb691",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 442221694,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 442221694,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9956ac0a20d7497bbb52774dc7128ab9"
          }
        },
        "1ffaa617975d43b1863fb6b1de7c09b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d2013e4af0dd46948520e000894b2266",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 442M/442M [00:08&lt;00:00, 53.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7603facb96754956a684bf71ebe4a088"
          }
        },
        "e6a3b17db176412082fd1ac974edb691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9956ac0a20d7497bbb52774dc7128ab9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d2013e4af0dd46948520e000894b2266": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7603facb96754956a684bf71ebe4a088": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0ATa8wJfO2D",
        "colab_type": "text"
      },
      "source": [
        "# Task 1A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmZ-gry-f0qc",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUSVIKaRnl2t",
        "colab_type": "code",
        "outputId": "24a1a5e8-d8e2-4114-d4b3-0a42f7748d8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/WING-NUS/scisumm-corpus.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'scisumm-corpus'...\n",
            "warning: --local is ignored\n",
            "remote: Enumerating objects: 107, done.\u001b[K\n",
            "remote: Counting objects: 100% (107/107), done.\u001b[K\n",
            "remote: Compressing objects: 100% (99/99), done.\u001b[K\n",
            "remote: Total 23215 (delta 57), reused 27 (delta 8), pack-reused 23108\u001b[K\n",
            "Receiving objects: 100% (23215/23215), 361.26 MiB | 31.68 MiB/s, done.\n",
            "Resolving deltas: 100% (6342/6342), done.\n",
            "Checking out files: 100% (16268/16268), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwZDvBo3FLlz",
        "colab_type": "code",
        "outputId": "1d8a2b17-5d1b-4b70-c161-72ed55f582ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYYcbcris6YF",
        "colab_type": "code",
        "outputId": "48698d4c-e7fb-4042-bc8f-73d310916a68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd scisumm-corpus/data/Training-Set-2019/Task1/From-ScisummNet-2019/\n",
        "X = !ls\n",
        "import re\n",
        "files = []\n",
        "for file in X:\n",
        "  Y = re.split(r'[ ,\\t]', file)\n",
        "  files += [y for y in Y if y!=\"\"]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/scisumm-corpus/data/Training-Set-2019/Task1/From-ScisummNet-2019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3gVuElyFFZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def lemmatized_text(text):\n",
        "  cleaned = re.sub('\\W+', ' ', text)\n",
        "  tokenized = word_tokenize(cleaned)\n",
        "\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  lemmatized = [lemmatizer.lemmatize(token) for token in tokenized]\n",
        "\n",
        "  return lemmatized"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5H9fPNUvLkd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "from bs4 import BeautifulSoup\n",
        "import random\n",
        "\n",
        "DataDict = defaultdict(lambda: {\"C_text\": [], \"R_text\": []})\n",
        "DataDict_negativesamples = defaultdict(lambda: {\"C_text\": [], \"R_text\": []})\n",
        "\n",
        "for rfile in files:\n",
        "  open_file = open(rfile+\"/annotation/\"+rfile+\".ann.txt\", 'r') \n",
        "  open_file_xml = open(rfile+\"/Reference_XML/\"+rfile+\".xml\", 'r') \n",
        "  references = open_file_xml.read()\n",
        "  citances = open_file.readlines()\n",
        "  for citance in citances:\n",
        "    if len(citance) > 1:\n",
        "      data_file = citance.split(\" | \")\n",
        "      if(len(data_file) == 11):\n",
        "        Reference_offset = data_file[7].split(\":\")[1].split(\"'\")\n",
        "        Reference_offset = [int(Reference_offset[i]) for i in range(len(Reference_offset)-1) if i%2 == 1]\n",
        "        soup = BeautifulSoup(data_file[6].split(\":\")[1])\n",
        "        ctexts = soup.find_all(\"s\")\n",
        "        C_Text_data = \"\"\n",
        "        for i in ctexts:\n",
        "          C_Text_data += \" \" + i.get_text()\n",
        "\n",
        "        soup = BeautifulSoup(references, \"xml\")\n",
        "        rtexts = soup.find_all(\"S\")\n",
        "        R_Text_data = \"\"\n",
        "        for i in Reference_offset:\n",
        "          R_Text_data += \" \" + rtexts[i].get_text()\n",
        "\n",
        "        Reference_offset_negativesamples = [random.randint(0,len(rtexts)-1), random.randint(0,len(rtexts)-1)]\n",
        "        R_Text_negativesample = \"\"\n",
        "        for i in Reference_offset_negativesamples:\n",
        "          R_Text_negativesample += \" \" + rtexts[i].get_text()\n",
        "\n",
        "        C_text = lemmatized_text(C_Text_data)\n",
        "        R_text = lemmatized_text(R_Text_data)\n",
        "        R_negativetext = lemmatized_text(R_Text_negativesample)\n",
        "\n",
        "        DataDict[data_file[1].split(\":\")[1]][\"C_text\"] += [\" \".join(C_text)]\n",
        "        DataDict[data_file[1].split(\":\")[1]][\"R_text\"] += [\" \".join(R_text)]\n",
        "\n",
        "        DataDict_negativesamples[data_file[1].split(\":\")[1]][\"C_text\"] += [\" \".join(C_text)]\n",
        "        DataDict_negativesamples[data_file[1].split(\":\")[1]][\"R_text\"] += [\" \".join(R_negativetext)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukeH2SnotXLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dict = dict(list(DataDict.items())[:int(len(DataDict)*75/100)])\n",
        "valid_dict = dict(list(DataDict.items())[int(len(DataDict)*75/100):])\n",
        "\n",
        "train_cdata = []\n",
        "train_rdata = []\n",
        "train_label = []\n",
        "for key in train_dict.keys():\n",
        "  train_cdata += [cdata for cdata in DataDict[key][\"C_text\"]]\n",
        "  train_rdata += [rdata for rdata in DataDict[key][\"R_text\"]]\n",
        "  train_label += [1 for i in range(len(DataDict[key][\"C_text\"]))]\n",
        "\n",
        "valid_cdata = []\n",
        "valid_rdata = []\n",
        "valid_label = []\n",
        "for key in valid_dict.keys():\n",
        "  valid_cdata += [cdata for cdata in DataDict[key][\"C_text\"]]\n",
        "  valid_rdata += [rdata for rdata in DataDict[key][\"R_text\"]]\n",
        "  valid_label += [1 for i in range(len(DataDict[key][\"C_text\"]))]\n",
        "\n",
        "train_dict = dict(list(DataDict_negativesamples.items())[:int(len(DataDict_negativesamples)*75/100)])\n",
        "valid_dict = dict(list(DataDict_negativesamples.items())[int(len(DataDict_negativesamples)*75/100):])\n",
        "\n",
        "for key in train_dict.keys():\n",
        "  train_cdata += [cdata for cdata in DataDict_negativesamples[key][\"C_text\"]]\n",
        "  train_rdata += [rdata for rdata in DataDict_negativesamples[key][\"R_text\"]]\n",
        "  train_label += [0 for i in range(len(DataDict_negativesamples[key][\"C_text\"]))]\n",
        "\n",
        "for key in valid_dict.keys():\n",
        "  valid_cdata += [cdata for cdata in DataDict_negativesamples[key][\"C_text\"]]\n",
        "  valid_rdata += [rdata for rdata in DataDict_negativesamples[key][\"R_text\"]]\n",
        "  valid_label += [0 for i in range(len(DataDict_negativesamples[key][\"C_text\"]))]\n",
        "\n",
        "datashuffle = list(zip(train_cdata, train_rdata, train_label))\n",
        "random.shuffle(datashuffle)\n",
        "train_cdata, train_rdata, train_label = zip(*datashuffle)\n",
        "\n",
        "datashuffle = list(zip(valid_cdata, valid_rdata, valid_label))\n",
        "random.shuffle(datashuffle)\n",
        "valid_cdata, valid_rdata, valid_label = zip(*datashuffle)\n",
        "\n",
        "train_data = {\"c_text\": train_cdata, \n",
        "              \"r_text\": train_rdata,\n",
        "              \"label\" : train_label}\n",
        "valid_data = {\"c_text\": valid_cdata, \n",
        "              \"r_text\": valid_rdata,\n",
        "              \"label\" : valid_label}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fXySuvSJpUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from torchtext.data import Field, BucketIterator, TabularDataset\n",
        "\n",
        "df = pd.DataFrame(train_data, columns=[\"c_text\", \"r_text\", \"label\"])\n",
        "df_val = pd.DataFrame(valid_data, columns=[\"c_text\", \"r_text\", \"label\"])\n",
        "\n",
        "df.to_csv(\"train.csv\", index=False)\n",
        "df_val.to_csv(\"val.csv\", index=False)\n",
        "\n",
        "data_fields = [('c_text', Field()), ('r_text', Field()), ('label', Field())]\n",
        "TrainData, ValData = TabularDataset.splits(path='./', train='train.csv', validation='val.csv', format='csv', fields=data_fields)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIvk6PvlSg59",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDj0ugwAf_ya",
        "colab_type": "text"
      },
      "source": [
        "### Loading the following Models for Sentence Embeddings\n",
        "\n",
        "\n",
        "*   Glove \n",
        "*   Bert Model \n",
        "    * bert-base-nli-mean-tokens\n",
        "    * Scibert Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCdvE1PmU09O",
        "colab_type": "code",
        "outputId": "c2223f9a-6dc4-4678-aeb7-0dff46d91d9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-02 06:53:44--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-05-02 06:53:44--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-05-02 06:53:45--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.27MB/s    in 6m 29s  \n",
            "\n",
            "2020-05-02 07:00:14 (2.12 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggkB7YnPVvuU",
        "colab_type": "code",
        "outputId": "22314c7f-7017-4738-f376-c5052428765d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        }
      },
      "source": [
        "!pip install sentence-transformers\n",
        "from sentence_transformers import SentenceTransformer\n",
        "bert_model = SentenceTransformer('bert-base-nli-mean-tokens')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/46/b7d6c37d92d1bd65319220beabe4df845434930e3f30e42d3cfaecb74dc4/sentence-transformers-0.2.6.1.tar.gz (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 4.8MB/s \n",
            "\u001b[?25hCollecting transformers>=2.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 23.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (4.38.0)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.5.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.18.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=2.8.0->sentence-transformers) (2.23.0)\n",
            "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /simple/sacremoses/\u001b[0m\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 15.7MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 49.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.8.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.8.0->sentence-transformers) (1.12.47)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.8.0->sentence-transformers) (0.7)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 51.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.8.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.1->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers) (1.12.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.8.0->sentence-transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.8.0->sentence-transformers) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.8.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.8.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.8.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.8.0->sentence-transformers) (1.15.47)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.8.0->sentence-transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.8.0->sentence-transformers) (0.3.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.47->boto3->transformers>=2.8.0->sentence-transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.47->boto3->transformers>=2.8.0->sentence-transformers) (0.15.2)\n",
            "Building wheels for collected packages: sentence-transformers, sacremoses\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.2.6.1-cp36-none-any.whl size=74031 sha256=da574eb6c66e7c0d3e4957ba4b73f6251c327c3729d9fdfede67a01488bf278e\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/fa/17/2b081a8cd8b0a86753fb0e9826b3cc19f0207062c0b2da7008\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=a9f15bde2f8cb8d7ca9707a5745a75aa9ebb0abc54d1b7f85d0c461ed9fd136c\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
            "Successfully built sentence-transformers sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers, sentence-transformers\n",
            "Successfully installed sacremoses-0.0.41 sentence-transformers-0.2.6.1 sentencepiece-0.1.86 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 405M/405M [00:05<00:00, 67.6MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnxDvzZovwdO",
        "colab_type": "code",
        "outputId": "1bbc2e24-b59d-424d-9277-f69f0e0822fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 822,
          "referenced_widgets": [
            "0e7bed5da6cf4b34803c7484e2e35d9f",
            "749f3875638c4c4da07659aa4d922617",
            "6ec7d043dcc94accbb5c79789ea6d3bd",
            "08c2f8ceb6a8483fa9304537f4a4314f",
            "d59699f8d54145b8a6cffc0ee7df2628",
            "a6017df065ac48e58647b525484421f8",
            "9cf9bc2b0b1e4106a0417c9ee7326cc1",
            "08ac88ba2b4e466aa77b50ccbaa23dbb",
            "bc12830b3dec4b9990ae35465fe4b1bf",
            "ff107716040342a59f9ea9744121fe16",
            "b6a4d2b7da6846a6bee0d67e3683eecd",
            "64c52d73b7af4ad4a926897a0c580d08",
            "d8b57092c4fa44f6a4fbe20d5f89cc48",
            "7f27a04fcea64fc8aeffb11ad54b4966",
            "728649b2a6144772a04067f6a5680133",
            "d8e3c6379d7b46c597ffffcbdee612e1",
            "c8c07a2238fa420a9424811fcd72a217",
            "d760618999c34c9f8c3dd42730f415f2",
            "4a9c68bd6e534bc39f4f70a424a5e621",
            "1ffaa617975d43b1863fb6b1de7c09b0",
            "e6a3b17db176412082fd1ac974edb691",
            "9956ac0a20d7497bbb52774dc7128ab9",
            "d2013e4af0dd46948520e000894b2266",
            "7603facb96754956a684bf71ebe4a088"
          ]
        }
      },
      "source": [
        "!pip install transformers\n",
        "from transformers import *\n",
        "scibert_tokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\n",
        "scibert_model = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\r\u001b[K     |▋                               | 10kB 16.8MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 1.9MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 2.3MB/s eta 0:00:01\r\u001b[K     |███▌                            | 61kB 2.7MB/s eta 0:00:01\r\u001b[K     |████                            | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 81kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 92kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 102kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 112kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████                         | 122kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 133kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 143kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 153kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 163kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 174kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 184kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 194kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 204kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 215kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 225kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 235kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 245kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 256kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 266kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 276kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 286kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 296kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 307kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 317kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 327kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 337kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 348kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 358kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 368kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 378kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 389kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 399kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 409kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 419kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 430kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 440kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 450kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 460kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 471kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 481kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 491kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 501kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 512kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 522kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 532kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 542kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 552kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 563kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 573kB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 16.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 14.9MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 44.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.3)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.47)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.47)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.47->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.47->boto3->transformers) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=6d3972d1560f963a1bd527eaa2b6b215fe4e3f8b6e2294ec6691062e275d4400\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.41 sentencepiece-0.1.86 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e7bed5da6cf4b34803c7484e2e35d9f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=385, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc12830b3dec4b9990ae35465fe4b1bf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=227845, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8c07a2238fa420a9424811fcd72a217",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=442221694, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viSJgxwUYlxa",
        "colab_type": "code",
        "outputId": "2d185030-aa49-4a61-a128-c01dbd8fbbc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%cd /content/\n",
        "%cd scisumm-corpus/data/Training-Set-2019/Task1/From-ScisummNet-2019/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/scisumm-corpus/data/Training-Set-2019/Task1/From-ScisummNet-2019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpLPMz2CgzpZ",
        "colab_type": "text"
      },
      "source": [
        "### Sentence Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86zOVZDblUsm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "embeddings_index = {}\n",
        "\n",
        "with open('glove.6B.300d.txt', encoding='utf8') as f:\n",
        "    for line in f:  \n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:],dtype='float32')\n",
        "        embeddings_index[word] = coefs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW7G-l8dAnc7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sen_glove_embedding(sen, device):\n",
        "\n",
        "  embedding = []\n",
        "  for w in sen:\n",
        "    if w in embeddings_index.keys():\n",
        "      embedding.append(embeddings_index[w.lower()])\n",
        "    else:\n",
        "      embedding.append(np.zeros((300,)))\n",
        "\n",
        "  sen_emb = np.sum(embedding, axis=0)  \n",
        "  return torch.FloatTensor([[sen_emb]]).to(device)\n",
        "\n",
        "def sen_bert_embedding(sen, device):\n",
        "  sen_t = []  \n",
        "  for w in sen:\n",
        "    if w:\n",
        "      sen_t.append(w)\n",
        "  sen = \" \".join(sen_t)\n",
        "  sen_bert_emb = bert_model.encode([sen])\n",
        "\n",
        "  return torch.FloatTensor([sen_bert_emb]).to(device)\n",
        "\n",
        "def sen_scibert_embedding(sen, device):\n",
        "  sen_t = []  \n",
        "  for w in sen:\n",
        "    if w:\n",
        "      sen_t.append(w)\n",
        "  sen = \" \".join(sen_t)\n",
        "  input_ids = torch.tensor([scibert_tokenizer.encode([sen], add_special_tokens=False)]) \n",
        "  with torch.no_grad():\n",
        "    sen_scibert_emb = scibert_model(input_ids)[0]\n",
        "\n",
        "  return sen_scibert_emb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3VI1-6rg5P3",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J8OFaj4351Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import time\n",
        "import math\n",
        "from sklearn import metrics\n",
        "\n",
        "def exponent_neg_manhattan_distance(citance, reference):\n",
        "    return torch.exp(-torch.sum(torch.abs(citance-reference), axis=2, keepdims=True))\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "class NNmodel(nn.Module):\n",
        "  def __init__(self, input_dim, sen_embedding, device):\n",
        "    super().__init__()\n",
        "    self.embedding_layer = sen_embedding\n",
        "    self.c_lstm_layer = nn.LSTM(input_dim, 300, 2)\n",
        "    self.c_connencted_layer = nn.Linear(300, 300)\n",
        "\n",
        "    self.Manhattan_dist = exponent_neg_manhattan_distance\n",
        "    self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    self.device = device\n",
        "  \n",
        "  def forward(self, citance_text, reference_text):\n",
        "    c_emb = self.embedding_layer(citance_text, self.device)\n",
        "    r_emb = self.embedding_layer(reference_text, self.device)\n",
        "\n",
        "    C_X, (hidden, cell) = self.c_lstm_layer(self.dropout(c_emb))\n",
        "    C_X = self.c_connencted_layer(C_X)\n",
        "\n",
        "    R_X, (hidden, cell) = self.c_lstm_layer(self.dropout(r_emb))\n",
        "    R_X = self.c_connencted_layer(R_X)\n",
        "\n",
        "    prob = self.Manhattan_dist(C_X, R_X)\n",
        "    return prob\n",
        "\n",
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.1, 0.1)\n",
        "\n",
        "def train(model, data, optimizer, criterion, clip):\n",
        "    model.train()\n",
        "    loss = 0\n",
        "\n",
        "    for i in data.examples:\n",
        "        c_text = vars(i)['c_text']\n",
        "        r_text = vars(i)['r_text']\n",
        "        label = vars(i)['label']\n",
        "        if label == [\"label\"] or len(c_text)==0 or len(r_text)==0:\n",
        "          continue\n",
        "        optimizer.zero_grad()\n",
        "        output = model(c_text, r_text)\n",
        "        loss = criterion(output, torch.FloatTensor([[int(label[0])]]).to(device))\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        loss += loss.item()\n",
        "        \n",
        "    # print(loss)\n",
        "    return loss / len(train_data)\n",
        "\n",
        "def evaluate(model, data, criterion):\n",
        "    model.eval()\n",
        "    loss = 0\n",
        "    pred = []\n",
        "    gt = []\n",
        "    with torch.no_grad():\n",
        "      for i in data.examples:\n",
        "          c_text = vars(i)['c_text']\n",
        "          r_text = vars(i)['r_text']\n",
        "          label = vars(i)['label']\n",
        "          if label == [\"label\"] or len(c_text)==0 or len(r_text)==0:\n",
        "            continue\n",
        "          \n",
        "          output = model(c_text, r_text)\n",
        "          pred.append(output.cpu())\n",
        "          gt.append(int(label[0])) \n",
        "          temp_loss = criterion(output, torch.FloatTensor([[int(label[0])]]).to(device))\n",
        "          loss += temp_loss.item()\n",
        "\n",
        "    pred = [1 if pred_.numpy() > 0.5 else 0 for pred_ in pred]\n",
        "    f1_score = metrics.f1_score(gt, pred)\n",
        "    precision = metrics.precision_score(gt, pred,zero_division=0)\n",
        "    recall = metrics.recall_score(gt, pred)\n",
        "    return loss / len(valid_data), f1_score, precision, recall "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um0mpiRvYVlF",
        "colab_type": "code",
        "outputId": "a5ec0050-dc8f-4032-dd28-466e7e3f17fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "###Running model corresponding to the BERT embeddings\n",
        "bertmodel = NNmodel(768, sen_bert_embedding, device).to(device)\n",
        "bertmodel.apply(init_weights)\n",
        "bertoptimizer = torch.optim.Adam(bertmodel.parameters())        \n",
        "bertcriterion = nn.MSELoss()\n",
        "\n",
        "\n",
        "print(\"Results for Bert based method\")\n",
        "\n",
        "N_EPOCHS = 1\n",
        "CLIP = 1\n",
        "best_valid_loss = float('inf')\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss = train(bertmodel, TrainData, bertoptimizer, bertcriterion, CLIP)\n",
        "    valid_loss, f1_score, precision, recall = evaluate(bertmodel, ValData, bertcriterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(bertmodel.state_dict(), 'bert-model.pt')\n",
        "    \n",
        "    print(f'\\tTime: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f}')\n",
        "    print(f'\\t Val. F1_score: {f1_score:.3f}')\n",
        "    print(f'\\t Val. Precision_score: {precision:.3f}')\n",
        "    print(f'\\t Val. Recall_score: {recall:.3f}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for Bert based method\n",
            "\tTime: 14m 9s\n",
            "\tTrain Loss: 0.029\n",
            "\t Val. Loss: 761.275\n",
            "\t Val. F1_score: 0.401\n",
            "\t Val. Precision_score: 0.767\n",
            "\t Val. Recall_score: 0.272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZfrp5y6Kpw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Loading the models and Computing the performance of the model\n",
        "bertmodel = NNmodel(768, sen_bert_embedding, device).to(device)\n",
        "bertcriterion = nn.MSELoss()\n",
        "bertmodel.load_state_dict(torch.load(\"bert-model.pt\"))\n",
        "bertmodel.eval()\n",
        "valid_loss, f1_score, precision, recall = evaluate(bertmodel, ValData, bertcriterion)\n",
        "print(\"Results for Bert based method\")\n",
        "print(f'\\t Val. Loss: {valid_loss:.3f}')\n",
        "print(f'\\t Val. F1_score: {f1_score:.3f}')\n",
        "print(f'\\t Val. Precision_score: {precision:.3f}')\n",
        "print(f'\\t Val. Recall_score: {recall:.3f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "731050a0-4564-4541-842b-eca2abbfa62c",
        "id": "dHwyJCm3aYOl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "###Running the model corresponding to the Glove embeddings\n",
        "glovemodel = NNmodel(300,sen_glove_embedding, device).to(device)\n",
        "glovemodel.apply(init_weights)\n",
        "gloveoptimizer = torch.optim.Adam(glovemodel.parameters())        \n",
        "glovecriterion = nn.MSELoss()\n",
        "\n",
        "print(\"Results for Glove based method\")\n",
        "N_EPOCHS = 1\n",
        "CLIP = 1\n",
        "best_valid_loss = float('inf')\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss = train(glovemodel, TrainData, gloveoptimizer, glovecriterion, CLIP)\n",
        "    valid_loss, f1_score, precision, recall = evaluate(glovemodel, ValData, glovecriterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(glovemodel.state_dict(), 'glove-model.pt')\n",
        "    \n",
        "    print(f'\\tTime: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f}')\n",
        "    print(f'\\t Val. F1_score: {f1_score:.3f}')\n",
        "    print(f'\\t Val. Precision_score: {precision:.3f}')\n",
        "    print(f'\\t Val. Recall_score: {recall:.3f}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for Glove based method\n",
            "\tTime: 2m 5s\n",
            "\tTrain Loss: 0.000\n",
            "\t Val. Loss: 634.723\n",
            "\t Val. F1_score: 0.601\n",
            "\t Val. Precision_score: 0.692\n",
            "\t Val. Recall_score: 0.531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBeC7zaUKIlA",
        "colab_type": "code",
        "outputId": "0bbe262d-1b8e-4502-898d-f3cbbea7a69e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "###Loading the models and Computing the performance of the model\n",
        "\n",
        "glovemodel = NNmodel(300,sen_glove_embedding,device).to(device)\n",
        "glovecriterion = nn.MSELoss()\n",
        "glovemodel.load_state_dict(torch.load(\"/content/glove-model.pt\"))\n",
        "glovemodel.eval()\n",
        "valid_loss, f1_score, precision, recall = evaluate(glovemodel, ValData, glovecriterion)\n",
        "print(\"Results for Glove based method\")\n",
        "print(f'\\t Val. Loss: {valid_loss:.3f}')\n",
        "print(f'\\t Val. F1_score: {f1_score:.3f}')\n",
        "print(f'\\t Val. Precision_score: {precision:.3f}')\n",
        "print(f'\\t Val. Recall_score: {recall:.3f}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:432: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Val. Loss: 1282.667\n",
            "\t Val. F1_score: 0.667\n",
            "\t Val. Precision_score: 0.500\n",
            "\t Val. Recall_score: 1.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlomnZrURQU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ###Running the model corresponding to the Glove embeddings\n",
        "\n",
        "# ###Scibert based embedding require a lot of time and more comutation power for training \n",
        "# ###therefore we have already trained the model and will use the loaded model for showing the performance\n",
        "\n",
        "# scibert-model = NNmodel(768,sen_scibert_embedding, device).to(device)\n",
        "# scibert-model.apply(init_weights)\n",
        "# scibert-optimizer = torch.optim.Adam(scibert-model.parameters())        \n",
        "# scibert-criterion = nn.MSELoss()\n",
        "\n",
        "# print(\"Results for SciBert based method\")\n",
        "\n",
        "# N_EPOCHS = 1\n",
        "# CLIP = 1\n",
        "# best_valid_loss = float('inf')\n",
        "# for epoch in range(N_EPOCHS):\n",
        "#     start_time = time.time()\n",
        "#     train_loss = train(glovemodel, TrainData, gloveoptimizer, glovecriterion, CLIP)\n",
        "#     valid_loss, f1_score, precision, recall = evaluate(glovemodel, ValData, criterion)\n",
        "    \n",
        "#     end_time = time.time()\n",
        "#     epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "#     if valid_loss < best_valid_loss:\n",
        "#         best_valid_loss = valid_loss\n",
        "#         torch.save(model.state_dict(), 'scibert-model.pt')\n",
        "    \n",
        "#     print(f'\\tTime: {epoch_mins}m {epoch_secs}s')\n",
        "#     print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "#     print(f'\\t Val. Loss: {valid_loss:.3f}')\n",
        "#     print(f'\\t Val. F1_score: {f1_score:.3f}')\n",
        "#     print(f'\\t Val. Precision_score: {precision:.3f}')\n",
        "#     print(f'\\t Val. Recall_score: {recall:.3f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tgp_Em_RR-sA",
        "colab_type": "code",
        "outputId": "9d18bccc-2caa-44ce-afa9-ba3ed4713ea1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# ##Loading the models and Computing the performance of the model\n",
        "# scibertmodel = NNmodel(768,sen_scibert_embedding,device).to(device)\n",
        "# scibertcriterion = nn.MSELoss()\n",
        "# scibertmodel.load_state_dict(torch.load(\"scibert-model.pt\"))\n",
        "# scibertmodel.eval()\n",
        "\n",
        "# valid_loss, f1_score, precision, recall = evaluate(scibertmodel, ValData, scibertcriterion)\n",
        "# print(f'\\t Val. Loss: {valid_loss:.3f}')\n",
        "# print(f'\\t Val. F1_score: {f1_score:.3f}')\n",
        "# print(f'\\t Val. Precision_score: {precision:.3f}')\n",
        "# print(f'\\t Val. Recall_score: {recall:.3f}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t Val. Loss: 1282.506\n",
            "\t Val. F1_score: 0.667\n",
            "\t Val. Precision_score: 0.500\n",
            "\t Val. Recall_score: 1.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfdU3VxuguAJ",
        "colab_type": "text"
      },
      "source": [
        "###Output Printing Matched Sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLGJISqOqbtD",
        "colab_type": "code",
        "outputId": "3586617e-d1c8-41ba-995f-a583103cb9e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/scisumm-corpus/data/Test-Set-2018/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/scisumm-corpus/data/Test-Set-2018\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaQcTUuW7eJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import glob\n",
        "import re\n",
        "\n",
        "files = []\n",
        "X = !ls\n",
        "for file in X:\n",
        "  Y = re.split(r'[ ,\\t]', file)\n",
        "  files += [y for y in Y if y!=\"\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nn6JrIvPYozz",
        "colab_type": "code",
        "outputId": "9391f66e-916f-4deb-a465-7c4c5d956313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import random\n",
        "index_no = random.randint(0,len(files))\n",
        "rfile = files[index_no]\n",
        "rfile = \"W99-0613\"\n",
        "print(\"For file : \", rfile)\n",
        "# for rfile in files[:1]:\n",
        "open_file = open(rfile+\"/Reference_XML/\"+rfile+\".xml\", 'r') \n",
        "references = open_file.read()\n",
        "with open(rfile+\"/annotation/\"+rfile+\".csv\", 'r') as file:\n",
        "  csv_file = csv.DictReader(file)\n",
        "  for row in csv_file:\n",
        "    c_text = row['Citation Text']\n",
        "    soup = BeautifulSoup(references, \"xml\")\n",
        "    rtexts = soup.find_all(\"S\")\n",
        "    outputs_bert = []\n",
        "    outputs_glove = []\n",
        "    outputs_scibert = []\n",
        "    rtext_bert_similairty = []\n",
        "    for i in rtexts:\n",
        "        r_text = i.get_text()\n",
        "        rtext_bert_similairty.append(r_text)\n",
        "        output = bertmodel(c_text, r_text)\n",
        "        outputs_bert.append(output)\n",
        "        glovemodel(c_text, r_text)\n",
        "        outputs_glove.append(output)\n",
        "        \n",
        "        # scibertmodel(c_text, r_text)\n",
        "        # outputs_scibert.append(output)\n",
        "    \n",
        "    print(\"\\n\\nQuery:\", c_text)\n",
        "    print(\"MATCHED CITED SPAN ::\")\n",
        "    matched_r_text = \".\\n \".join([rtexts[indx].get_text() for indx in np.argsort(outputs_bert)[-2:]])\n",
        "    print(\"FOR BERT MODEL ::\\n\",matched_r_text)\n",
        "    matched_r_text = \".\\n \".join([rtexts[indx].get_text() for indx in np.argsort(outputs_glove)[-2:]])\n",
        "    print(\"FOR GLOVE MODEL ::\\n\",matched_r_text)\n",
        "    # matched_r_text = \".\\n \".join([rtexts[indx].get_text() for indx in np.argsort(outputs_scibert)[-2:]])\n",
        "    # print(\"\\nFOR SCIBERT MODEL\",matched_r_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For file :  W99-0613\n",
            "\n",
            "\n",
            "Query: Co-Training has been used before in applications like word-sense disambiguation (Yarowsky, 1995), web-page classification (Blum and Mitchell, 1998) and named entity identification (Collins and Singer, 1999)\n",
            "MATCHED CITED SPAN ::\n",
            "FOR BERT MODEL ::\n",
            " (Yarowsky 95) describes an algorithm for word-sense disambiguation that exploits redundancy in contextual features, and gives impressive performance..\n",
            " Recent results (e.g., (Yarowsky 95; Brill 95; Blum and Mitchell 98)) have suggested that unlabeled data can be used quite profitably in reducing the need for supervision.\n",
            "FOR GLOVE MODEL ::\n",
            " (Yarowsky 95) describes an algorithm for word-sense disambiguation that exploits redundancy in contextual features, and gives impressive performance..\n",
            " Recent results (e.g., (Yarowsky 95; Brill 95; Blum and Mitchell 98)) have suggested that unlabeled data can be used quite profitably in reducing the need for supervision.\n",
            "\n",
            "\n",
            "Query: They also discuss an application of classifying web pages by using their method of mutually constrained models. (Collins and Singer, 1999) further extend the use of classifiers that have mutual constraints by adding terms toAdaBoost which force the classifiers to agree (called Co Boosting)\n",
            "MATCHED CITED SPAN ::\n",
            "FOR BERT MODEL ::\n",
            " More recently, (Riloff and Jones 99) describe a method they term &quot;mutual bootstrapping&quot; for simultaneously constructing a lexicon and contextual extraction patterns..\n",
            " We can now add a new weak hypothesis 14 based on a feature in X1 with a confidence value al hl and atl are chosen to minimize the function We now define, for 1 <i <n, the following virtual distribution, As before, Ztl is a normalization constant.\n",
            "FOR GLOVE MODEL ::\n",
            " More recently, (Riloff and Jones 99) describe a method they term &quot;mutual bootstrapping&quot; for simultaneously constructing a lexicon and contextual extraction patterns..\n",
            " We can now add a new weak hypothesis 14 based on a feature in X1 with a confidence value al hl and atl are chosen to minimize the function We now define, for 1 <i <n, the following virtual distribution, As before, Ztl is a normalization constant.\n",
            "\n",
            "\n",
            "Query: Recent methods for English NER focus on machine-learning algorithms such as DL-CoTrain, CoBoost [Collins and Singer 1999], HMM [Daniel M. Bikel 1997], maximum entropy model [Borthwick, et al 1999] and so on\n",
            "MATCHED CITED SPAN ::\n",
            "FOR BERT MODEL ::\n",
            " The CoBoost algorithm just described is for the case where there are two labels: for the named entity task there are three labels, and in general it will be useful to generalize the CoBoost algorithm to the multiclass case..\n",
            " The method halves the error rate in comparison to a method using the labeled examples alone.\n",
            "FOR GLOVE MODEL ::\n",
            " The CoBoost algorithm just described is for the case where there are two labels: for the named entity task there are three labels, and in general it will be useful to generalize the CoBoost algorithm to the multiclass case..\n",
            " The method halves the error rate in comparison to a method using the labeled examples alone.\n",
            "\n",
            "\n",
            "Query: DL-CoTrain, (Collins and Singer, 1999), learns capitalized proper name NEs from a syn tactically analyzed corpus\n",
            "MATCHED CITED SPAN ::\n",
            "FOR BERT MODEL ::\n",
            " We can now add a new weak hypothesis 14 based on a feature in X1 with a confidence value al hl and atl are chosen to minimize the function We now define, for 1 <i <n, the following virtual distribution, As before, Ztl is a normalization constant..\n",
            " In this work we extended the AdaBoost.MH (Schapire and Singer 98) algorithm to the cotraining case.\n",
            "FOR GLOVE MODEL ::\n",
            " We can now add a new weak hypothesis 14 based on a feature in X1 with a confidence value al hl and atl are chosen to minimize the function We now define, for 1 <i <n, the following virtual distribution, As before, Ztl is a normalization constant..\n",
            " In this work we extended the AdaBoost.MH (Schapire and Singer 98) algorithm to the cotraining case.\n",
            "\n",
            "\n",
            "Query: (Collins and Singer, 1999) also makes use of competing categories (person, organization, and location), which cover 96% of all the instances itset out to classify\n",
            "MATCHED CITED SPAN ::\n",
            "FOR BERT MODEL ::\n",
            " 971,746 sentences of New York Times text were parsed using the parser of (Collins 96).1 Word sequences that met the following criteria were then extracted as named entity examples: whose head is a singular noun (tagged NN)..\n",
            " The first method builds on results from (Yarowsky 95) and (Blum and Mitchell 98).\n",
            "FOR GLOVE MODEL ::\n",
            " 971,746 sentences of New York Times text were parsed using the parser of (Collins 96).1 Word sequences that met the following criteria were then extracted as named entity examples: whose head is a singular noun (tagged NN)..\n",
            " The first method builds on results from (Yarowsky 95) and (Blum and Mitchell 98).\n",
            "\n",
            "\n",
            "Query: In (Collins and Singer, 1999) Collins and Singer show that unlabeled data can be used to reduce the level of supervision required for named entity classification\n",
            "MATCHED CITED SPAN ::\n",
            "FOR BERT MODEL ::\n",
            " The final strong hypothesis, denoted 1(x), is then the sign of a weighted sum of the weak hypotheses, 1(x) = sign (Vii atht(x)), where the weights at are determined during the run of the algorithm, as we describe below..\n",
            " The key point is that the second constraint can be remarkably powerful in reducing the complexity of the learning problem.\n",
            "FOR GLOVE MODEL ::\n",
            " The final strong hypothesis, denoted 1(x), is then the sign of a weighted sum of the weak hypotheses, 1(x) = sign (Vii atht(x)), where the weights at are determined during the run of the algorithm, as we describe below..\n",
            " The key point is that the second constraint can be remarkably powerful in reducing the complexity of the learning problem.\n",
            "\n",
            "\n",
            "Query: Collins and Singer (1999) for example report that 88% of the named entities occurring in their data set belong to these three categories (Collins and Singer, 1999)\n",
            "MATCHED CITED SPAN ::\n",
            "FOR BERT MODEL ::\n",
            " (Brin 98) ,describes a system for extracting (author, book-title) pairs from the World Wide Web using an approach that bootstraps from an initial seed set of examples..\n",
            " (Blum and Mitchell 98) describe learning in the following situation: X = X1 X X2 where X1 and X2 correspond to two different &quot;views&quot; of an example.\n",
            "FOR GLOVE MODEL ::\n",
            " (Brin 98) ,describes a system for extracting (author, book-title) pairs from the World Wide Web using an approach that bootstraps from an initial seed set of examples..\n",
            " (Blum and Mitchell 98) describe learning in the following situation: X = X1 X X2 where X1 and X2 correspond to two different &quot;views&quot; of an example.\n",
            "\n",
            "\n",
            "Query: While EM has worked quite well for a few tasks, notably ma chine translations (starting with the IBM models 1-5 (Brown et al, 1993), it has not had success inmost others, such as part-of-speech tagging (Merialdo, 1991), named-entity recognition (Collinsand Singer, 1999) and context-free-grammar induction (numerous attempts, too many to mention)\n",
            "MATCHED CITED SPAN ::\n",
            "FOR BERT MODEL ::\n",
            " There has been additional recent work on inducing lexicons or other knowledge sources from large corpora..\n",
            " The second modification is more important, and is discussed in the next section.\n",
            "FOR GLOVE MODEL ::\n",
            " There has been additional recent work on inducing lexicons or other knowledge sources from large corpora..\n",
            " The second modification is more important, and is discussed in the next section.\n",
            "\n",
            "\n",
            "Query: In addition, we would also like to explore the semi-supervised techniques such as co-training and self-training (Collins and Singer, 1999)\n",
            "MATCHED CITED SPAN ::\n",
            "FOR BERT MODEL ::\n",
            " AdaBoost was first introduced in (Freund and Schapire 97); (Schapire and Singer 98) gave a generalization of AdaBoost which we will use in this paper..\n",
            " To see this, note thai the first two terms in the above equation correspond to the function that AdaBoost attempts to minimize in the standard supervised setting (Equ.\n",
            "FOR GLOVE MODEL ::\n",
            " AdaBoost was first introduced in (Freund and Schapire 97); (Schapire and Singer 98) gave a generalization of AdaBoost which we will use in this paper..\n",
            " To see this, note thai the first two terms in the above equation correspond to the function that AdaBoost attempts to minimize in the standard supervised setting (Equ.\n",
            "\n",
            "\n",
            "Query: Collins et al (Collins and Singer, 1999) proposed two algorithms for NER by modifying Yarowsky ?smethod (Yarowsky, 1995) and the framework suggested by (Blum and Mitchell, 1998)\n",
            "MATCHED CITED SPAN ::\n",
            "FOR BERT MODEL ::\n",
            " The task is to learn a function from an input string (proper name) to its type, which we will assume to be one of the categories Person, Organization, or Location..\n",
            " (Yarowsky 95) describes an algorithm for word-sense disambiguation that exploits redundancy in contextual features, and gives impressive performance.\n",
            "FOR GLOVE MODEL ::\n",
            " The task is to learn a function from an input string (proper name) to its type, which we will assume to be one of the categories Person, Organization, or Location..\n",
            " (Yarowsky 95) describes an algorithm for word-sense disambiguation that exploits redundancy in contextual features, and gives impressive performance.\n",
            "\n",
            "\n",
            "Query: This approach was shown to perform well on real-world natural language problems (Collins and Singer, 1999)\n",
            "MATCHED CITED SPAN ::\n",
            "FOR BERT MODEL ::\n",
            " Pseudo-code describing the generalized boosting algorithm of Schapire and Singer is given in Figure 1..\n",
            " Then, it can be verified that We can now derive the CoBoost algorithm as a means of minimizing Zco.\n",
            "FOR GLOVE MODEL ::\n",
            " Pseudo-code describing the generalized boosting algorithm of Schapire and Singer is given in Figure 1..\n",
            " Then, it can be verified that We can now derive the CoBoost algorithm as a means of minimizing Zco.\n",
            "\n",
            "\n",
            "Query: (6) Similarly to (Collins and Singer, 1999) we used T= 0.95 for all experiments reported here\n",
            "MATCHED CITED SPAN ::\n",
            "FOR BERT MODEL ::\n",
            " The first method builds on results from (Yarowsky 95) and (Blum and Mitchell 98)..\n",
            " Recent results (e.g., (Yarowsky 95; Brill 95; Blum and Mitchell 98)) have suggested that unlabeled data can be used quite profitably in reducing the need for supervision.\n",
            "FOR GLOVE MODEL ::\n",
            " The first method builds on results from (Yarowsky 95) and (Blum and Mitchell 98)..\n",
            " Recent results (e.g., (Yarowsky 95; Brill 95; Blum and Mitchell 98)) have suggested that unlabeled data can be used quite profitably in reducing the need for supervision.\n",
            "\n",
            "\n",
            "Query: We use Collins and Singer (1999) for our exact specification of Yarowsky.2 It uses DL rule scores ?fj?| ?fj |+ \u000f|? f |+ L\u000f (1) where \u000f is a smoothing constant\n",
            "MATCHED CITED SPAN ::\n",
            "FOR BERT MODEL ::\n",
            " The key point is that the second constraint can be remarkably powerful in reducing the complexity of the learning problem..\n",
            " To see this, note thai the first two terms in the above equation correspond to the function that AdaBoost attempts to minimize in the standard supervised setting (Equ.\n",
            "FOR GLOVE MODEL ::\n",
            " The key point is that the second constraint can be remarkably powerful in reducing the complexity of the learning problem..\n",
            " To see this, note thai the first two terms in the above equation correspond to the function that AdaBoost attempts to minimize in the standard supervised setting (Equ.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsT7dzagjRvH",
        "colab_type": "text"
      },
      "source": [
        "######Tried Fine Tuning for Bert model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOvOfxXumz-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###We tried fine tuning the Bert model but due to ram issues couldn't proceed to train the model\n",
        "\n",
        "# from torch.utils.data import DataLoader\n",
        "# import math\n",
        "# from sentence_transformers import SentenceTransformer,  SentencesDataset, LoggingHandler, losses\n",
        "# from sentence_transformers.readers import TripletReader\n",
        "# from sentence_transformers.evaluation import TripletEvaluator\n",
        "# import logging\n",
        "# from datetime import datetime\n",
        "# import csv\n",
        "\n",
        "\n",
        "# triplet_reader = TripletReader('.', s1_col_idx=0, s2_col_idx=1, s3_col_idx=2, delimiter=',', quoting=csv.QUOTE_MINIMAL, has_header=True)\n",
        "# train_data = SentencesDataset(triplet_reader.get_examples('train.csv'), bert_model)\n",
        "# train_batch_size = 100\n",
        "# train_dataloader = DataLoader(train_data, shuffle=True, batch_size=train_batch_size)\n",
        "# train_loss = losses.CosineSimilarityLoss(model=bert_model)\n",
        "\n",
        "# dev_data = SentencesDataset(triplet_reader.get_examples('val.csv'), bert_model)\n",
        "# dev_dataloader = DataLoader(dev_data, shuffle=True, batch_size=train_batch_size)\n",
        "# evaluator = TripletEvaluator(dev_dataloader)\n",
        "\n",
        "# num_epochs=1\n",
        "\n",
        "# warmup_steps = 1\n",
        "# # warmup_steps = int(len(train_data)*num_epochs/train_batch_size*0.1)\n",
        "\n",
        "# bert_model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
        "#           evaluator=evaluator,\n",
        "#           epochs=num_epochs,\n",
        "#           evaluation_steps=10,\n",
        "#           warmup_steps=warmup_steps,\n",
        "#           output_path=\"bertfinetuning.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZtEqf1_kMsC",
        "colab_type": "text"
      },
      "source": [
        "### Getting Span based on Similairty"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09r8hn3XhCBx",
        "colab_type": "code",
        "outputId": "00006f96-18b9-471c-c1a5-f98adb5ce39d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "!pip install spicy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spicy\n",
            "  Downloading https://files.pythonhosted.org/packages/10/f7/58fd43678e56f6eed4b4a186dba367be3b56f95bb5a15741a0bf9861dde4/spicy-0.16.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from spicy) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->spicy) (1.18.3)\n",
            "Installing collected packages: spicy\n",
            "Successfully installed spicy-0.16.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joE20_zqFZgi",
        "colab_type": "code",
        "outputId": "25dbb965-4343-4467-930f-419fd6f215a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "from scipy.spatial import distance as distance_cal\n",
        "\n",
        "def cosine_similarity(query, sentence):\n",
        "  query_embedding = bert_model.encode([query])\n",
        "  sentence_embeddings = bert_model.encode([sentence])\n",
        "  distances = distance_cal.cdist(query_embedding, sentence_embeddings, \"cosine\")[0]\n",
        "  return distances[0]\n",
        "\n",
        "bert_model.eval()\n",
        "pred = []\n",
        "gt = []\n",
        "with torch.no_grad():\n",
        "  for i in ValData.examples:\n",
        "      c_text = vars(i)['c_text']\n",
        "      r_text = vars(i)['r_text']\n",
        "      label = vars(i)['label']\n",
        "      if label == [\"label\"] or len(c_text)==0 or len(r_text)==0:\n",
        "        continue\n",
        "      cs = cosine_similarity(\" \".join(c_text), \" \".join(r_text))\n",
        "      pred.append(cs)\n",
        "      gt.append(int(label[0]))\n",
        "\n",
        "pred = [1 if pred_ > 0.5 else 0 for pred_ in pred]\n",
        "\n",
        "loss = metrics.mean_squared_error(gt, pred)\n",
        "f1_score = metrics.f1_score(gt, pred)\n",
        "precision = metrics.precision_score(gt, pred,zero_division=0)\n",
        "recall = metrics.recall_score(gt, pred)\n",
        "\n",
        "print(f'\\t Val. Loss: {loss:.3f}')\n",
        "print(f'\\t Val. F1_score: {f1_score:.3f}')\n",
        "print(f'\\t Val. Precision_score: {precision:.3f}')\n",
        "print(f'\\t Val. Recall_score: {recall:.3f}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t Val. Loss: 0.626\n",
            "\t Val. F1_score: 0.215\n",
            "\t Val. Precision_score: 0.289\n",
            "\t Val. Recall_score: 0.172\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krlMEG7_0TFW",
        "colab_type": "code",
        "outputId": "b8139f4e-9dd0-47a5-a952-026c4947b6a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/scisumm-corpus/data/Test-Set-2018/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/scisumm-corpus/data/Test-Set-2018\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS6zIW6N4Mb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def matched_sent(queries, sentences):\n",
        "  query_embedding = bert_model.encode([queries])\n",
        "  sentence_embeddings = bert_model.encode(sentences)\n",
        "  number_top_matches = 3\n",
        "  distances = distance_cal.cdist(query_embedding, sentence_embeddings, \"cosine\")[0]\n",
        "\n",
        "  results = zip(range(len(distances)), distances)\n",
        "  results = sorted(results, key=lambda x: x[1])\n",
        "\n",
        "  print(\"\\nQuery:\", queries)\n",
        "  print(\"Top 3 most similar sentences in corpus can form the span:\")\n",
        "\n",
        "  for idx, distance in results[0:number_top_matches]:\n",
        "      print(sentences[idx].strip(), \"(Cosine Score: %.4f)\" % (1-distance))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82n0oZheknWL",
        "colab_type": "code",
        "outputId": "e894b536-9bbc-430b-c236-8ca847329c7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "index_no = random.randint(0,len(files))\n",
        "rfile = files[index_no]\n",
        "# rfile = \"W99-0613\"\n",
        "# for rfile in files[:1]:\n",
        "open_file = open(rfile+\"/Reference_XML/\"+rfile+\".xml\", 'r') \n",
        "references = open_file.read()\n",
        "with open(rfile+\"/annotation/\"+rfile+\".csv\", 'r') as file:\n",
        "  csv_file = csv.DictReader(file)\n",
        "  for row in csv_file:\n",
        "    c_text = row['Citation Text']\n",
        "    soup = BeautifulSoup(references, \"xml\")\n",
        "    rtexts = soup.find_all(\"S\")\n",
        "    outputs = []\n",
        "    rtext_bert_similairty = []\n",
        "    for i in rtexts:\n",
        "        r_text = i.get_text()\n",
        "        rtext_bert_similairty.append(r_text)      \n",
        "    matched_sent(c_text, rtext_bert_similairty)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Query: Finally, we note that simple weighting gives nearly a 2% F1 improvement, whereas Goldberg and Tsarfaty (2008) found that unweighted lattices were more effective for Hebrew\n",
            "Top 3 most similar sentences in corpus can form the span:\n",
            "Using a treebank grammar, a data-driven lexicon, and a linguistically motivated unknown-tokens handling technique our model outperforms previous pipelined, integrated or factorized systems for Hebrew morphological and syntactic processing, yielding an error reduction of 12% over the best published results so far. (Cosine Score: 0.8067)\n",
            "Morphological disambiguators that consider a token in context (an utterance) and propose the most likely morphological analysis of an utterance (including segmentation) were presented by Bar-Haim et al. (2005), Adler and Elhadad (2006), Shacham and Wintner (2007), and achieved good results (the best segmentation result so far is around 98%). (Cosine Score: 0.7148)\n",
            "Secondly, for all our models we provide better fine- and coarse-grained POS-tagging accuracy, and all pruned models outperform the Oracle results reported by them.12 In terms of syntactic disambiguation, even the simplest grammar pruned with HSPELL outperforms their non-Oracle results. (Cosine Score: 0.7106)\n",
            "\n",
            "Query: Goldberg and Tsarfaty (2008) showed that a single model for morphological segmentation and syntactic parsing of Hebrew yielded an error reduction of 12% over the best pipelined models\n",
            "Top 3 most similar sentences in corpus can form the span:\n",
            "Using a treebank grammar, a data-driven lexicon, and a linguistically motivated unknown-tokens handling technique our model outperforms previous pipelined, integrated or factorized systems for Hebrew morphological and syntactic processing, yielding an error reduction of 12% over the best published results so far. (Cosine Score: 0.9359)\n",
            "Tsarfaty and Sima’an (2007) have reported state-of-the-art results on Hebrew unlexicalized parsing (74.41%) albeit assuming oracle morphological segmentation. (Cosine Score: 0.7355)\n",
            "Secondly, for all our models we provide better fine- and coarse-grained POS-tagging accuracy, and all pruned models outperform the Oracle results reported by them.12 In terms of syntactic disambiguation, even the simplest grammar pruned with HSPELL outperforms their non-Oracle results. (Cosine Score: 0.6814)\n",
            "\n",
            "Query: Zhang and Clark (2008) built a perceptron-based joint segmenter and part-of-speech (POS) tagger for Chinese, and Toutanova and Cherry (2009) learned a joint model of lemmatization and POS tagging which outperformed a pipelined model. Adler and Elhadad (2006) presented an HMMbased approach for unsupervised joint morphological segmentation and tagging of Hebrew, and Goldberg and Tsarfaty (2008) developed a joint model of segmentation, tagging and parsing of He brew, based on lattice parsing\n",
            "Top 3 most similar sentences in corpus can form the span:\n",
            "Morphological analyzers for Hebrew that analyze a surface form in isolation have been proposed by Segal (2000), Yona and Wintner (2005), and recently by the knowledge center for processing Hebrew (Itai et al., 2006). (Cosine Score: 0.7551)\n",
            "Tsarfaty and Sima’an (2007) have reported state-of-the-art results on Hebrew unlexicalized parsing (74.41%) albeit assuming oracle morphological segmentation. (Cosine Score: 0.7299)\n",
            "Morphological segmentation decisions in our model are delegated to a lexeme-based PCFG and we show that using a simple treebank grammar, a data-driven lexicon, and a linguistically motivated unknown-tokens handling our model outperforms (Tsarfaty, 2006) and (Cohen and Smith, 2007) on the joint task and achieves state-of-the-art results on a par with current respective standalone models.2 (Cosine Score: 0.6956)\n",
            "\n",
            "Query: Goldberg and Tsarfaty (2008) pro pose a generative joint model\n",
            "Top 3 most similar sentences in corpus can form the span:\n",
            "In our forth model GTnph we add the definiteness status of constituents following Tsarfaty and Sima’an (2007). (Cosine Score: 0.7354)\n",
            "We further report SYNCS, the parsing metric of Cohen and Smith (2007), to facilitate the comparison. (Cosine Score: 0.6841)\n",
            "Our parsing performance measures (SY N) thus report the PARSEVAL extension proposed in Tsarfaty (2006). (Cosine Score: 0.6829)\n",
            "\n",
            "Query: Goldberg and Tsarfaty (2008) concluded that an integrated model of morphological disambiguation and syntactic parsing in Hebrew Treebank parsing improves the results of a pipelined approach\n",
            "Top 3 most similar sentences in corpus can form the span:\n",
            "The table makes clear that enriching our grammar improves the syntactic performance as well as morphological disambiguation (segmentation and POS tagging) accuracy. (Cosine Score: 0.8218)\n",
            "Tsarfaty (2006) used a morphological analyzer (Segal, 2000), a PoS tagger (Bar-Haim et al., 2005), and a general purpose parser (Schmid, 2000) in an integrated framework in which morphological and syntactic components interact to share information, leading to improved performance on the joint task. (Cosine Score: 0.8067)\n",
            "Tsarfaty (2006) argues that for Semitic languages determining the correct morphological segmentation is dependent on syntactic context and shows that increasing information sharing between the morphological and the syntactic components leads to improved performance on the joint task. (Cosine Score: 0.7766)\n",
            "\n",
            "Query: Goldberg and Tsarfaty (2008) demonstrated the effectiveness of lattice parsing for jointly performing segmentation and parsing of Hebrewtext\n",
            "Top 3 most similar sentences in corpus can form the span:\n",
            "Tsarfaty (2006) used a morphological analyzer (Segal, 2000), a PoS tagger (Bar-Haim et al., 2005), and a general purpose parser (Schmid, 2000) in an integrated framework in which morphological and syntactic components interact to share information, leading to improved performance on the joint task. (Cosine Score: 0.7357)\n",
            "To evaluate the performance on the segmentation task, we report SEG, the standard harmonic means for segmentation Precision and Recall F1 (as defined in Bar-Haim et al. (2005); Tsarfaty (2006)) as well as the segmentation accuracy SEGTok measure indicating the percentage of input tokens assigned the correct exact segmentation (as reported by Cohen and Smith (2007)). (Cosine Score: 0.7211)\n",
            "A possible probabilistic model for assigning probabilities to complex analyses of a surface form may be and indeed recent sequential disambiguation models for Hebrew (Adler and Elhadad, 2006) and Arabic (Smith et al., 2005) present similar models. (Cosine Score: 0.7184)\n",
            "\n",
            "Query: Following (Goldberg and Tsarfaty, 2008) we deal with the ambiguous affixation patterns in Hebrew by encoding the input sentence as a segmentation lattice\n",
            "Top 3 most similar sentences in corpus can form the span:\n",
            "A morphological analyzer M : W—* L is a function mapping sentences in Hebrew (W E W) to their corresponding lattices (M(W) = L E L). (Cosine Score: 0.8387)\n",
            "Morphological analyzers for Hebrew that analyze a surface form in isolation have been proposed by Segal (2000), Yona and Wintner (2005), and recently by the knowledge center for processing Hebrew (Itai et al., 2006). (Cosine Score: 0.8095)\n",
            "We simulate lexical constraints by using an external lexical resource against which we verify whether OOV segments are in fact valid Hebrew lexemes. (Cosine Score: 0.8080)\n",
            "\n",
            "Query: 2The complete set of analyses for this word is provided in Goldberg and Tsarfaty (2008)\n",
            "Top 3 most similar sentences in corpus can form the span:\n",
            "In our forth model GTnph we add the definiteness status of constituents following Tsarfaty and Sima’an (2007). (Cosine Score: 0.7841)\n",
            "We further report SYNCS, the parsing metric of Cohen and Smith (2007), to facilitate the comparison. (Cosine Score: 0.6924)\n",
            "Our parsing performance measures (SY N) thus report the PARSEVAL extension proposed in Tsarfaty (2006). (Cosine Score: 0.6884)\n",
            "\n",
            "Query: A study that is closely related toours is (Goldberg and Tsarfaty, 2008), where a single generative model was proposed for joint morphological segmentation and syntactic parsing for Hebrew\n",
            "Top 3 most similar sentences in corpus can form the span:\n",
            "Morphological analyzers for Hebrew that analyze a surface form in isolation have been proposed by Segal (2000), Yona and Wintner (2005), and recently by the knowledge center for processing Hebrew (Itai et al., 2006). (Cosine Score: 0.8503)\n",
            "A morphological analyzer M : W—* L is a function mapping sentences in Hebrew (W E W) to their corresponding lattices (M(W) = L E L). (Cosine Score: 0.7884)\n",
            "Data We use the Hebrew Treebank, (Sima’an et al., 2001), provided by the knowledge center for processing Hebrew, in which sentences from the daily newspaper “Ha’aretz” are morphologically segmented and syntactically annotated. (Cosine Score: 0.7353)\n",
            "\n",
            "Query: Models that in addition incorporate morphological analysis and segmentation have been explored by Tsarfaty (2006), Cohen and Smith (2007), and Goldberg and Tsarfaty (2008) with special reference to Hebrew parsing\n",
            "Top 3 most similar sentences in corpus can form the span:\n",
            "Morphological analyzers for Hebrew that analyze a surface form in isolation have been proposed by Segal (2000), Yona and Wintner (2005), and recently by the knowledge center for processing Hebrew (Itai et al., 2006). (Cosine Score: 0.8196)\n",
            "A possible probabilistic model for assigning probabilities to complex analyses of a surface form may be and indeed recent sequential disambiguation models for Hebrew (Adler and Elhadad, 2006) and Arabic (Smith et al., 2005) present similar models. (Cosine Score: 0.7978)\n",
            "We further report SYNCS, the parsing metric of Cohen and Smith (2007), to facilitate the comparison. (Cosine Score: 0.7419)\n",
            "\n",
            "Query: 4), and in a more realistic one in which parsing and segmentation are handled jointly by the parser (Goldberg and Tsarfaty, 2008) (Sec\n",
            "Top 3 most similar sentences in corpus can form the span:\n",
            "Tsarfaty (2006) used a morphological analyzer (Segal, 2000), a PoS tagger (Bar-Haim et al., 2005), and a general purpose parser (Schmid, 2000) in an integrated framework in which morphological and syntactic components interact to share information, leading to improved performance on the joint task. (Cosine Score: 0.7624)\n",
            "Cohen and Smith (2007) followed up on these results and proposed a system for joint inference of morphological and syntactic structures using factored models each designed and trained on its own. (Cosine Score: 0.7525)\n",
            "Cohen and Smith (2007) later on based a system for joint inference on factored, independent, morphological and syntactic components of which scores are combined to cater for the joint inference task. (Cosine Score: 0.7502)\n",
            "\n",
            "Query: It is the same grammar as described in (Goldberg and Tsarfaty, 2008)\n",
            "Top 3 most similar sentences in corpus can form the span:\n",
            "Lexical rules are estimated in a similar manner. (Cosine Score: 0.7175)\n",
            "This is by now a fairly standard representation for multiple morphological segmentation of Hebrew utterances (Adler, 2001; Bar-Haim et al., 2005; Smith et al., 2005; Cohen and Smith, 2007; Adler, 2007). (Cosine Score: 0.7092)\n",
            "The same argument holds for resolving PP attachment of a prefixed preposition or marking conjunction of elements of any kind. (Cosine Score: 0.7000)\n",
            "\n",
            "Query: Several studies followed this line, (Cohen and Smith, 2007) the most recent of which is Goldberg and Tsarfaty (2008), who presented a model based on unweighted lattice parsing for performing the joint task\n",
            "Top 3 most similar sentences in corpus can form the span:\n",
            "Cohen and Smith (2007) followed up on these results and proposed a system for joint inference of morphological and syntactic structures using factored models each designed and trained on its own. (Cosine Score: 0.7448)\n",
            "In our third model GTppp we also add the distinction between general PPs and possessive PPs following Goldberg and Elhadad (2007). (Cosine Score: 0.7369)\n",
            "We further report SYNCS, the parsing metric of Cohen and Smith (2007), to facilitate the comparison. (Cosine Score: 0.7030)\n",
            "\n",
            "Query: Goldberg and Tsarfaty (2008) use a data-driven morphological analyzer derived from the tree bank\n",
            "Top 3 most similar sentences in corpus can form the span:\n",
            "This analyzer setting is similar to that of (Cohen and Smith, 2007), and models using it are denoted nohsp, Parser and Grammar We used BitPar (Schmid, 2004), an efficient general purpose parser,10 together with various treebank grammars to parse the input sentences and propose compatible morphological segmentation and syntactic analysis. (Cosine Score: 0.6975)\n",
            "Morphological Analyzer Ideally, we would use an of-the-shelf morphological analyzer for mapping each input token to its possible analyses. (Cosine Score: 0.6795)\n",
            "Cohen and Smith (2007) followed up on these results and proposed a system for joint inference of morphological and syntactic structures using factored models each designed and trained on its own. (Cosine Score: 0.6781)\n",
            "\n",
            "Query: The model of Goldberg and Tsarfaty (2008) uses a morphological analyzer to constructs a lattice for each input token\n",
            "Top 3 most similar sentences in corpus can form the span:\n",
            "In sequential tagging models such as (Adler and Elhadad, 2006; Bar-Haim et al., 2007; Smith et al., 2005) weights are assigned according to a language model The input for the joint task is a sequence W = w1, ... , wn of space-delimited tokens. (Cosine Score: 0.7915)\n",
            "The Input The set of analyses for a token is thus represented as a lattice in which every arc corresponds to a specific lexeme l, as shown in Figure 1. (Cosine Score: 0.7890)\n",
            "Morphological Analyzer Ideally, we would use an of-the-shelf morphological analyzer for mapping each input token to its possible analyses. (Cosine Score: 0.7730)\n",
            "\n",
            "Query: Instead, we use the evaluation measure of (Tsarfaty, 2006), also used in (Goldberg and Tsarfaty, 2008), which is an adaptation of parse val to use characters instead of space-delimited tokens as its basic units\n",
            "Top 3 most similar sentences in corpus can form the span:\n",
            "We use the HSPELL9 (Har’el and Kenigsberg, 2004) wordlist as a lexeme-based lexicon for pruning segmentations involving invalid segments. (Cosine Score: 0.7833)\n",
            "To facilitate the comparison of our results to those reported by (Cohen and Smith, 2007) we use their data set in which 177 empty and “malformed”7 were removed. (Cosine Score: 0.7323)\n",
            "When a token fmnh is to be interpreted as the lexeme sequence f/REL mnh/VB, the analysis introduces two distinct entities, the relativizer f (“that”) and the verb mnh (“counted”), and not as the complex entity “that counted”. (Cosine Score: 0.7261)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}